{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from utils import prepare_save_dir\n",
    "# from STELLAR import STELLAR\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "# from datasets import GraphDataset\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--use-processed-graph'], dest='use_processed_graph', nargs=None, const=None, default=False, type=<class 'bool'>, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='STELLAR')\n",
    "parser.add_argument('--dataset', default='TonsilBE', help='dataset setting')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S', help='random seed (default: 1)')\n",
    "parser.add_argument('--name', type=str, default='STELLAR')\n",
    "parser.add_argument('--epochs', type=int, default=50)\n",
    "parser.add_argument('--lr', type=float, default=1e-3) # learning rate\n",
    "parser.add_argument('--wd', type=float, default=5e-2) # weight decay\n",
    "parser.add_argument('--num-heads', type=int, default=13)\n",
    "parser.add_argument('--num-seed-class', type=int, default=3)\n",
    "parser.add_argument('--sample-rate', type=float, default=0.5) # downsample dataset by using 50% of cells\n",
    "parser.add_argument('-b', '--batch-size', default=1, type=int,\n",
    "                metavar='N', help='mini-batch size')\n",
    "parser.add_argument('--distance_thres', default=50, type=int)# distance threshold for constructing the graph\n",
    "parser.add_argument('--savedir', type=str, default='./') # output directory\n",
    "\n",
    "parser.add_argument('--use-processed-graph', type=bool, default=False) # whether to use already preprocessed graph or construct the graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(args=[])\n",
    "args.cuda = torch.cuda.is_available()\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/region1_2_healthy_mouse_lymph_simplified.csv')\n",
    "train_df = df.loc[df['region'] == 1]\n",
    "test_df = df.loc[df['region'] == 2]\n",
    "train_y = train_df['cluster'].str.lower()\n",
    "test_y = test_df['cluster'].str.lower()\n",
    "cell_types = np.sort(list(set(test_y))).tolist()\n",
    "cell_type_dict = {}\n",
    "for i, cell_type in enumerate(cell_types):\n",
    "    cell_type_dict[cell_type] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/region1_2_healthy_mouse_lymph_simplified.csv')\n",
    "train_df = df.loc[df['region'] == 1]\n",
    "test_df = df.loc[df['region'] == 2]\n",
    "train_y = train_df['cluster'].str.lower()\n",
    "test_y = test_df['cluster'].str.lower()\n",
    "cell_types_train = np.sort(list(set(train_y))).tolist()\n",
    "class_train = [i for i in range(len(cell_types_train))]\n",
    "cell_type_dict_train = {}\n",
    "inverse_dict_train = {}\n",
    "cell_types_test = np.sort(list(set(test_y))).tolist()\n",
    "cell_type_dict_test = {}\n",
    "inverse_dict_test = {}\n",
    "for i, cell_type in enumerate(cell_types_train):\n",
    "    cell_type_dict_train[cell_type] = i\n",
    "    inverse_dict_train[i] = cell_type\n",
    "for i, cell_type in enumerate(cell_types_test):\n",
    "    cell_type_dict_test[cell_type] = i\n",
    "    inverse_dict_test[i] = cell_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b-cell',\n",
       " 'cd206+ lymphatic vessels',\n",
       " 'cortical sinuses',\n",
       " 'dc',\n",
       " 'endothelial vessels',\n",
       " 'eosinophils',\n",
       " 'macrophage',\n",
       " 'neutrophils',\n",
       " 'nk cells',\n",
       " 't-cell',\n",
       " 'undefined']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_types_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 'b-cell',\n",
       "  1: 'cd206+ lymphatic vessels',\n",
       "  2: 'cortical sinuses',\n",
       "  3: 'dc',\n",
       "  4: 'endothelial vessels',\n",
       "  5: 'eosinophils',\n",
       "  6: 'macrophage',\n",
       "  7: 'neutrophils',\n",
       "  8: 'nk cells',\n",
       "  9: 't-cell',\n",
       "  10: 'undefined'},\n",
       " {0: 'b-cell',\n",
       "  1: 'dc',\n",
       "  2: 'endothelial vessels',\n",
       "  3: 'eosinophils',\n",
       "  4: 'lyve1+ lymphatic vessels',\n",
       "  5: 'macrophage',\n",
       "  6: 'monocytes',\n",
       "  7: 'neutrophils',\n",
       "  8: 'nk cells',\n",
       "  9: 't-cell',\n",
       "  10: 'unannotated'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_dict_train, inverse_dict_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_loaded = np.load('./experiments/run/MouseLymph_epoch_320_batch_32_wd_1e-05_results.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label = []\n",
    "for i,j in enumerate(array_loaded):\n",
    "    if j not in class_train:\n",
    "        pred_label.append('novel')\n",
    "    else:\n",
    "        pred_label.append(inverse_dict_train[j])\n",
    "# final = np.array([test_y,pred_label]).T\n",
    "# print(len(final))\n",
    "# final = np.delete(final,np.where(final == 'novel')[0],axis = 0)\n",
    "# final = np.delete(final,np.where(~((final == 'glandular_epi') | (final == 'secretory_epithelial') | (final == 'paneth')))[0],axis = 0)\n",
    "# row_idx, col_idx = np.where(~((final == 'glandular_epi') | (final == 'secretory_epithelial') | (final == 'paneth')))\n",
    "# print(len(final))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23544    macrophage\n",
       "23545    macrophage\n",
       "23546        b-cell\n",
       "23547    macrophage\n",
       "23548        b-cell\n",
       "            ...    \n",
       "41136    macrophage\n",
       "41137    macrophage\n",
       "41138    macrophage\n",
       "41139    macrophage\n",
       "41140    macrophage\n",
       "Name: cluster, Length: 17597, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['macrophage',\n",
       " 'macrophage',\n",
       " 'b-cell',\n",
       " 'macrophage',\n",
       " 'undefined',\n",
       " 'b-cell',\n",
       " 'b-cell',\n",
       " 'b-cell',\n",
       " 'macrophage',\n",
       " 'b-cell']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_label[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'label': test_y, 'pred': pred_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23544</th>\n",
       "      <td>macrophage</td>\n",
       "      <td>macrophage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23545</th>\n",
       "      <td>macrophage</td>\n",
       "      <td>macrophage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23546</th>\n",
       "      <td>b-cell</td>\n",
       "      <td>b-cell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23547</th>\n",
       "      <td>macrophage</td>\n",
       "      <td>macrophage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23548</th>\n",
       "      <td>b-cell</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label        pred\n",
       "23544  macrophage  macrophage\n",
       "23545  macrophage  macrophage\n",
       "23546      b-cell      b-cell\n",
       "23547  macrophage  macrophage\n",
       "23548      b-cell   undefined"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_results_matrix(result_df):\n",
    "    # novel_cell_types = ['glandular_epi', 'secretory_epithelial', 'paneth']\n",
    "    novel_cell_types = ['undefined']\n",
    "    # drop novel cell types from the results df\n",
    "    result_df_known = result_df.loc[~result_df['label'].isin(novel_cell_types)]\n",
    "\n",
    "    return result_df_known\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_known = preprocess_results_matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "t-cell                      5919\n",
       "b-cell                      5660\n",
       "macrophage                  1988\n",
       "dc                          1591\n",
       "endothelial vessels         1344\n",
       "unannotated                  471\n",
       "lyve1+ lymphatic vessels     401\n",
       "nk cells                      79\n",
       "monocytes                     64\n",
       "eosinophils                   40\n",
       "neutrophils                   40\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_known['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "t-cell                      5967\n",
       "b-cell                      5218\n",
       "macrophage                  2210\n",
       "dc                          1454\n",
       "endothelial vessels          912\n",
       "undefined                    748\n",
       "cortical sinuses             653\n",
       "eosinophils                  153\n",
       "cd206+ lymphatic vessels     115\n",
       "nk cells                      86\n",
       "neutrophils                   81\n",
       "Name: pred, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_known['pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohith/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/rohith/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/rohith/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/rohith/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                  b-cell       0.93      0.86      0.89      5660\n",
      "cd206+ lymphatic vessels       0.00      0.00      0.00         0\n",
      "        cortical sinuses       0.00      0.00      0.00         0\n",
      "                      dc       0.69      0.63      0.66      1591\n",
      "     endothelial vessels       0.77      0.52      0.62      1344\n",
      "             eosinophils       0.25      0.97      0.40        40\n",
      "lyve1+ lymphatic vessels       0.00      0.00      0.00       401\n",
      "              macrophage       0.68      0.76      0.72      1988\n",
      "               monocytes       0.00      0.00      0.00        64\n",
      "             neutrophils       0.46      0.93      0.61        40\n",
      "                nk cells       0.78      0.85      0.81        79\n",
      "                  t-cell       0.87      0.88      0.88      5919\n",
      "             unannotated       0.00      0.00      0.00       471\n",
      "               undefined       0.00      0.00      0.00         0\n",
      "\n",
      "                accuracy                           0.76     17597\n",
      "               macro avg       0.39      0.46      0.40     17597\n",
      "            weighted avg       0.80      0.76      0.78     17597\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohith/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/rohith/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "# metrics = precision_recall_fscore_support(final[:,0],final[:,1],average = 'weighted')\n",
    "classification = classification_report(df_known['label'], df_known['pred'])\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yunseokj/opt/anaconda3/envs/stellar/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yunseokj/opt/anaconda3/envs/stellar/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yunseokj/opt/anaconda3/envs/stellar/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yunseokj/opt/anaconda3/envs/stellar/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                  b-cell       0.91      0.88      0.89      5660\n",
      "cd206+ lymphatic vessels       0.00      0.00      0.00         0\n",
      "        cortical sinuses       0.00      0.00      0.00         0\n",
      "                      dc       0.71      0.63      0.67      1591\n",
      "     endothelial vessels       0.79      0.52      0.63      1344\n",
      "             eosinophils       0.31      1.00      0.48        40\n",
      "lyve1+ lymphatic vessels       0.00      0.00      0.00       401\n",
      "              macrophage       0.70      0.76      0.73      1988\n",
      "               monocytes       0.00      0.00      0.00        64\n",
      "             neutrophils       0.55      0.93      0.69        40\n",
      "                nk cells       0.77      0.84      0.80        79\n",
      "                  t-cell       0.87      0.87      0.87      5919\n",
      "             unannotated       0.00      0.00      0.00       471\n",
      "               undefined       0.00      0.00      0.00         0\n",
      "\n",
      "                accuracy                           0.77     17597\n",
      "               macro avg       0.40      0.46      0.41     17597\n",
      "            weighted avg       0.79      0.77      0.78     17597\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yunseokj/opt/anaconda3/envs/stellar/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yunseokj/opt/anaconda3/envs/stellar/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "classification = classification_report(df['label'], df['pred'])\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0.00,\n",
    "0.90, \n",
    "0.77, \n",
    "0.03, \n",
    "0.00,    \n",
    "0.84,  \n",
    "0.95, \n",
    "0.96, \n",
    "0.70, \n",
    "0.86, \n",
    "0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [\n",
    "0.90, \n",
    "0.77, \n",
    "0.03,     \n",
    "0.84,  \n",
    "0.95, \n",
    "0.96, \n",
    "0.70, \n",
    "0.86, \n",
    "0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6327272727272728"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(a) / len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7733333333333334"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(b) / len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                     precision    recall  f1-score   support\\n\\n                  b       0.00      0.00      0.00         0\\n        endothelial       0.38      0.96      0.54      6181\\n             innate       0.97      0.89      0.93      4282\\n              nerve       0.91      0.94      0.93      2047\\n              novel       0.00      0.00      0.00         0\\n               pdpn       0.98      0.65      0.78       914\\n             plasma       0.95      0.95      0.95      1177\\n       smoothmuscle       0.00      0.00      0.00      9023\\nsquamous_epithelial       0.99      0.56      0.72      1077\\n             stroma       0.86      0.85      0.85      4218\\n                  t       0.97      0.93      0.95      1416\\n\\n           accuracy                           0.62     30335\\n          macro avg       0.64      0.61      0.60     30335\\n       weighted avg       0.54      0.62      0.55     30335\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                  b       0.00      0.00      0.00         0\n",
      "        endothelial       0.38      0.96      0.54      6181\n",
      "             innate       0.97      0.89      0.93      4282\n",
      "              nerve       0.91      0.94      0.93      2047\n",
      "              novel       0.00      0.00      0.00         0\n",
      "               pdpn       0.98      0.65      0.78       914\n",
      "             plasma       0.95      0.95      0.95      1177\n",
      "       smoothmuscle       0.00      0.00      0.00      9023\n",
      "squamous_epithelial       0.99      0.56      0.72      1077\n",
      "             stroma       0.86      0.85      0.85      4218\n",
      "                  t       0.97      0.93      0.95      1416\n",
      "\n",
      "           accuracy                           0.62     30335\n",
      "          macro avg       0.64      0.61      0.60     30335\n",
      "       weighted avg       0.54      0.62      0.55     30335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "bca69d69fb1549edd980428a98d79bcd4d614577b37d70a5ea59882922728df6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
